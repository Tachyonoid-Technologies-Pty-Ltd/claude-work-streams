# Stream Archaeology Agent: Architecture Diagrams
## Visual Design Documentation for Work Streams v1.3.0

**Date:** 2025-11-02
**Version:** 1.0
**Companion Document:** v1.3.0-stream-archaeology-agent.md

---

## Table of Contents

1. [System Architecture Overview](#1-system-architecture-overview)
2. [Agent Collaboration Flow](#2-agent-collaboration-flow)
3. [Git Analysis Pipeline](#3-git-analysis-pipeline)
4. [Context Management Strategy](#4-context-management-strategy)
5. [Stream Boundary Detection Algorithm](#5-stream-boundary-detection-algorithm)
6. [User Interaction Flow](#6-user-interaction-flow)
7. [Session Memory Management](#7-session-memory-management)
8. [Sub-Agent Architecture](#8-sub-agent-architecture)
9. [Progressive Disclosure UX](#9-progressive-disclosure-ux)
10. [Integration with Existing Streams](#10-integration-with-existing-streams)
11. [Error Handling Decision Tree](#11-error-handling-decision-tree)
12. [Data Flow Diagram](#12-data-flow-diagram)

---

## 1. System Architecture Overview

```mermaid
graph TB
    subgraph "User Interface"
        CLI["/stream-init --analyze-history"]
        Progress["Progress Display"]
        Review["Interactive Review"]
    end

    subgraph "Stream Archaeology Agent"
        Coordinator["Coordinator Agent<br/>(Main Orchestrator)"]

        subgraph "Analysis Modules"
            Git["Git Analysis Module"]
            Semantic["Semantic Parser"]
            Codebase["Codebase Analyzer"]
        end

        subgraph "Intelligence Layer"
            Boundary["Boundary Detector"]
            Generator["Stream Generator"]
            Context["Context Manager"]
        end

        subgraph "Storage Layer"
            Memory["Memory Store<br/>(.claude/analysis/)"]
            Streams["Stream Database<br/>(.claude/streams/)"]
        end
    end

    subgraph "Data Sources"
        GitRepo["Git Repository"]
        Files["Codebase Files"]
    end

    CLI --> Coordinator
    Coordinator --> Progress
    Coordinator --> Git
    Coordinator --> Semantic
    Coordinator --> Codebase

    Git --> GitRepo
    Codebase --> Files

    Git --> Boundary
    Semantic --> Boundary
    Boundary --> Generator
    Generator --> Context

    Context --> Memory
    Generator --> Streams

    Streams --> Review
    Review --> CLI

    style Coordinator fill:#4a9eff
    style Git fill:#90ee90
    style Semantic fill:#90ee90
    style Codebase fill:#90ee90
    style Memory fill:#ffd700
    style Streams fill:#ffd700
```

---

## 2. Agent Collaboration Flow

**Based on Anthropic's Sub-Agent Architecture**

```mermaid
sequenceDiagram
    participant User
    participant Coordinator as Coordinator Agent
    participant GitAgent as Git Archaeology Agent
    participant SemanticAgent as Semantic Analysis Agent
    participant SynthesisAgent as Stream Synthesis Agent
    participant Memory as Memory Store

    User->>Coordinator: /stream-init --analyze-history

    Coordinator->>GitAgent: Analyze git history
    Note over GitAgent: Process 247 commits<br/>Generate patterns<br/>Isolate context
    GitAgent->>Memory: Store git patterns (500 tokens)
    GitAgent-->>Coordinator: Summary (1,000 tokens)

    Coordinator->>SemanticAgent: Parse commit messages
    SemanticAgent->>Memory: Load git patterns
    Note over SemanticAgent: Categorize by type<br/>Extract scope & subject<br/>Clean context
    SemanticAgent->>Memory: Store categories (300 tokens)
    SemanticAgent-->>Coordinator: Summary (800 tokens)

    Coordinator->>SynthesisAgent: Generate streams
    SynthesisAgent->>Memory: Load all summaries
    Note over SynthesisAgent: Detect boundaries<br/>Generate YAML<br/>Calculate confidence
    SynthesisAgent->>Memory: Store streams (200 tokens)
    SynthesisAgent-->>Coordinator: Stream list (500 tokens)

    Coordinator->>User: Present results<br/>(Total context: 2,300 tokens)
    User->>Coordinator: Approve
    Coordinator->>Memory: Finalize streams
    Memory-->>User: Streams created
```

**Key Pattern:** Each sub-agent works in isolation with clean context, reports compressed summaries (1,000-2,000 tokens) to coordinator.

---

## 3. Git Analysis Pipeline

```mermaid
flowchart LR
    subgraph "Input"
        Repo[Git Repository]
    end

    subgraph "Stage 1: Extract"
        LogCmd["git log --all<br/>--format='%H|%an|%ad|%s'<br/>--stat --numstat"]
        Tags["git log --tags<br/>--simplify-by-decoration"]
        Branches["git branch -a"]
    end

    subgraph "Stage 2: Parse"
        CommitParser["Commit Parser<br/>Hash, Author, Date,<br/>Message, Stats"]
        SemanticParser["Semantic Parser<br/>Type, Scope, Subject"]
        FileTracker["File Change Tracker<br/>Additions, Deletions"]
    end

    subgraph "Stage 3: Analyze"
        Pattern["Pattern Detection<br/>Work rhythms,<br/>Time gaps"]
        Author["Author Analysis<br/>Individual workflows"]
        Timeline["Timeline Builder<br/>Project evolution"]
    end

    subgraph "Stage 4: Classify"
        Features["Feature Streams<br/>(feat: commits)"]
        Bugs["Bug-Fix Streams<br/>(fix: commits)"]
        Refactor["Refactoring Streams<br/>(refactor: commits)"]
        Docs["Documentation Streams<br/>(docs: commits)"]
    end

    subgraph "Output"
        Boundaries["Stream Boundaries"]
        Metadata["Stream Metadata"]
    end

    Repo --> LogCmd
    Repo --> Tags
    Repo --> Branches

    LogCmd --> CommitParser
    CommitParser --> SemanticParser
    CommitParser --> FileTracker

    SemanticParser --> Pattern
    FileTracker --> Pattern
    Pattern --> Author
    Author --> Timeline

    Timeline --> Features
    Timeline --> Bugs
    Timeline --> Refactor
    Timeline --> Docs

    Features --> Boundaries
    Bugs --> Boundaries
    Refactor --> Boundaries
    Docs --> Boundaries

    Boundaries --> Metadata

    style LogCmd fill:#e1f5ff
    style Pattern fill:#fff3cd
    style Features fill:#d4edda
    style Boundaries fill:#ffd700
```

---

## 4. Context Management Strategy

**Based on OpenAI's SummarizingSession Pattern**

```mermaid
graph TD
    subgraph "Analysis Session"
        T1["Turn 1:<br/>Analyze commits 1-100"]
        T2["Turn 2:<br/>Analyze commits 101-200"]
        T3["Turn 3:<br/>Analyze commits 201-247"]
        T4["...Turn 20"]
        T21["Turn 21: TRIGGER"]
    end

    subgraph "Context Window (164k tokens)"
        Recent["Recent 5 Turns<br/>(Verbatim)"]
        Summary["Compressed Summary<br/>(400-600 tokens)"]
        Available["Available Space:<br/>~120k tokens"]
    end

    subgraph "External Memory"
        YAML1["analysis-batch-1.yaml"]
        YAML2["analysis-batch-2.yaml"]
        YAML3["analysis-batch-3.yaml"]
        YAML4["..."]
    end

    T1 --> YAML1
    T2 --> YAML2
    T3 --> YAML3
    T4 --> YAML4

    T21 -->|Context Limit Reached| Summarize

    Summarize["Summarization Engine"]
    Summarize -->|Compress Turns 1-15| Summary

    T21 --> Recent
    T4 --> Recent
    T3 --> Recent
    T2 --> Recent

    Summary --> Available
    Recent --> Available

    YAML1 -.->|Persistent Storage| Recovery["Recovery on<br/>Session Restart"]
    YAML2 -.->|Persistent Storage| Recovery
    YAML3 -.->|Persistent Storage| Recovery
    YAML4 -.->|Persistent Storage| Recovery

    style T21 fill:#ff6b6b
    style Summarize fill:#ffd700
    style Summary fill:#90ee90
    style Recovery fill:#4a9eff
```

**Key Points:**
- **Context Limit:** 20 turns before summarization
- **Keep Last N:** 5 most recent turns verbatim
- **Summary Size:** 400-600 tokens optimal
- **External Storage:** Survives context rotation

---

## 5. Stream Boundary Detection Algorithm

```mermaid
flowchart TD
    Start([Start: Next Commit])
    Parse[Parse Commit<br/>Type, Scope, Date]

    IsFeat{Type = 'feat'?}
    IsTimegap{Days since<br/>last > 3?}
    IsFix{Type = 'fix'?}
    IsRefactor{Type = 'refactor'?}

    CurrentExists{Current<br/>Stream Exists?}
    CurrentType{Current Stream<br/>Type?}

    SaveCurrent[Save Current Stream<br/>to Stream List]
    CreateFeature[Create New Stream<br/>Type: Feature]
    CreateBugFix[Create New Stream<br/>Type: Bug-Fix]
    CreateRefactor[Create New Stream<br/>Type: Refactoring]
    AppendCurrent[Append Commit<br/>to Current Stream]

    MoreCommits{More<br/>Commits?}
    End([End: Return Stream List])

    Start --> Parse
    Parse --> IsFeat

    IsFeat -->|Yes| CurrentExists
    CurrentExists -->|Yes| SaveCurrent
    CurrentExists -->|No| CreateFeature
    SaveCurrent --> CreateFeature
    CreateFeature --> MoreCommits

    IsFeat -->|No| IsTimegap
    IsTimegap -->|Yes| CurrentExists
    IsTimegap -->|No| IsFix

    IsFix -->|Yes| CurrentType
    CurrentType -->|Bug-Fix| AppendCurrent
    CurrentType -->|Other| SaveCurrent
    SaveCurrent --> CreateBugFix
    CreateBugFix --> MoreCommits

    IsFix -->|No| IsRefactor
    IsRefactor -->|Yes| CurrentType
    CurrentType -->|Refactoring| AppendCurrent
    CurrentType -->|Other| CreateRefactor

    IsRefactor -->|No| AppendCurrent
    AppendCurrent --> MoreCommits

    MoreCommits -->|Yes| Start
    MoreCommits -->|No| End

    style IsFeat fill:#4a9eff
    style IsTimegap fill:#ff9800
    style SaveCurrent fill:#ffd700
    style End fill:#90ee90
```

**Rules:**
1. `feat:` commits → New feature stream
2. Time gap >3 days → Stream boundary
3. Consecutive `fix:` commits → Bug-fix stream
4. Consecutive `refactor:` commits → Refactoring stream
5. Other commits → Append to current stream

---

## 6. User Interaction Flow

```mermaid
stateDiagram-v2
    [*] --> Command: User runs /stream-init --analyze-history

    Command --> Scanning: Confirm analysis
    Scanning --> Parsing: Git log scanned (247 commits)
    Parsing --> Detecting: Commits parsed & categorized
    Detecting --> Preview: Streams detected (12 streams)

    Preview --> ReviewStream: User: "preview"
    ReviewStream --> Confirm: User reviews details

    Preview --> Generate: User: "yes"
    Confirm --> Generate: User: "yes"

    Preview --> Cancel: User: "no"
    ReviewStream --> Skip: User: "skip"

    Confirm --> Edit: User: "edit"
    Edit --> Confirm: Changes saved

    Generate --> Creating: Generating YAML files
    Creating --> Summary: 12 streams created
    Summary --> [*]: Complete

    Cancel --> [*]: Cancelled
    Skip --> Preview: Next stream

    note right of Scanning
        Shows: Commit count,
        date range, authors
    end note

    note right of Preview
        Shows: Stream list with
        confidence scores
    end note

    note right of ReviewStream
        Shows: Full stream
        details, goals,
        checkpoints
    end note
```

**Progressive Disclosure Pattern:**
- Start simple (confirm analysis)
- Show summary (high-level results)
- Drill down on request (preview details)
- User control at each step (yes/no/preview/edit)

---

## 7. Session Memory Management

**Context Lifecycle Across Long-Running Analysis**

```mermaid
timeline
    title Analysis Session Context Lifecycle (20+ Turns)

    section Turns 1-5
        T1 : Analyze commits 1-50 : Context: 20k tokens
        T2 : Analyze commits 51-100 : Context: 35k tokens
        T3 : Analyze commits 101-150 : Context: 48k tokens
        T4 : Analyze commits 151-200 : Context: 62k tokens
        T5 : Analyze commits 201-247 : Context: 75k tokens

    section Turns 6-10
        T6 : Detect boundaries : Context: 88k tokens
        T7 : Extract goals : Context: 102k tokens
        T8 : Generate checkpoints : Context: 115k tokens
        T9 : Synthesize stream 1-4 : Context: 128k tokens
        T10 : Synthesize stream 5-8 : Context: 142k tokens

    section Turns 11-15
        T11 : Synthesize stream 9-12 : Context: 155k tokens (WARNING)
        T12 : Review results : Context: 158k tokens (CRITICAL)
        T13 : User confirmation : Context: 160k tokens (LIMIT)
        T14 : AUTO-COMPACT WOULD TRIGGER HERE : Prevented by summarization

    section Summarization Event
        T15 : SUMMARIZATION : Compress T1-T10 into 500 tokens
        T16 : Continue with clean context : Context: 65k tokens (HEALTHY)

    section Post-Summarization
        T17 : Generate YAML files : Context: 78k tokens
        T18 : Finalize streams : Context: 85k tokens
        T19 : Display summary : Context: 88k tokens
        T20 : Complete : Context: 90k tokens
```

**Key Transitions:**
- **Turn 11-13:** Context approaching limit (155-160k)
- **Turn 15:** Summarization prevents auto-compact
- **Turn 16+:** Clean context, work continues seamlessly

---

## 8. Sub-Agent Architecture

**Isolating Complex Analysis Tasks**

```mermaid
graph TB
    subgraph "Coordinator Agent Context"
        MainCtx["Main Context<br/>Clean & Minimal<br/>~30k tokens"]
    end

    subgraph "Git Archaeology Agent"
        GitCtx["Isolated Context<br/>~80k tokens"]
        GitWork["Heavy Processing:<br/>- Parse 247 commits<br/>- Build timeline<br/>- Detect patterns"]
        GitSummary["Summary:<br/>1,000 tokens<br/>Key patterns only"]
    end

    subgraph "Semantic Analysis Agent"
        SemCtx["Isolated Context<br/>~60k tokens"]
        SemWork["Heavy Processing:<br/>- Parse all messages<br/>- Categorize types<br/>- Extract scopes"]
        SemSummary["Summary:<br/>800 tokens<br/>Categories & counts"]
    end

    subgraph "Stream Synthesis Agent"
        SynthCtx["Isolated Context<br/>~50k tokens"]
        SynthWork["Heavy Processing:<br/>- Generate YAML<br/>- Create checkpoints<br/>- Calculate confidence"]
        SynthSummary["Summary:<br/>500 tokens<br/>Stream list only"]
    end

    MainCtx -->|Task 1| GitCtx
    GitWork --> GitSummary
    GitSummary -->|Report| MainCtx

    MainCtx -->|Task 2| SemCtx
    SemWork --> SemSummary
    SemSummary -->|Report| MainCtx

    MainCtx -->|Task 3| SynthCtx
    SynthWork --> SynthSummary
    SynthSummary -->|Report| MainCtx

    MainCtx -->|Final: 2,300 tokens total| User

    style MainCtx fill:#4a9eff
    style GitSummary fill:#90ee90
    style SemSummary fill:#90ee90
    style SynthSummary fill:#90ee90
```

**Benefits:**
- **Isolation:** Each agent has clean context for its task
- **Compression:** Only summaries returned to coordinator
- **Scalability:** Can process unlimited commits without context overflow
- **Modularity:** Agents can be improved independently

---

## 9. Progressive Disclosure UX

**Based on 2025 Onboarding Best Practices**

```mermaid
journey
    title User Experience Journey

    section Initial Contact
        Run command: 3: User
        See project info: 4: System
        Confirm analysis: 5: User

    section Analysis Phase
        Watch progress bar: 4: System
        See phase updates: 5: System
        Wait (2-3 min): 3: User

    section Results Preview
        See stream count: 5: System
        View stream list: 5: System
        Assess confidence: 4: System

    section Interactive Review
        Choose to preview: 5: User
        See stream details: 5: System
        Decide to approve: 5: User

    section Generation
        Watch creation: 4: System
        See success message: 5: System
        View summary: 5: System

    section Post-Generation
        Explore streams: 5: User
        Use Work Streams: 5: User
```

**Satisfaction Curve:**
- ✓ Quick start (single command)
- ✓ Clear progress (no black box)
- ✓ User control (preview/edit options)
- ✓ Fast value (2-3 minutes to usable streams)

---

## 10. Integration with Existing Streams

```mermaid
graph LR
    subgraph "Before Analysis"
        PreManual1["current-feature/<br/>stream.yaml<br/>(Manual)"]
        PreManual2["bug-fix-auth/<br/>stream.yaml<br/>(Manual)"]
    end

    subgraph "Analysis Process"
        Analyze["Stream Archaeology<br/>Agent"]
        Check{Name<br/>Conflicts?}
        Resolve["Conflict<br/>Resolution"]
    end

    subgraph "After Analysis"
        PostManual1["current-feature/<br/>stream.yaml<br/>(Manual - Unchanged)"]
        PostManual2["bug-fix-auth/<br/>stream.yaml<br/>(Manual - Unchanged)"]
        PostArch1["initial-setup/<br/>stream.yaml<br/>(Archaeological)"]
        PostArch2["v1.0.0-release/<br/>stream.yaml<br/>(Archaeological)"]
        PostArch3["database-migration/<br/>stream.yaml<br/>(Archaeological)"]
    end

    PreManual1 -.->|Preserved| PostManual1
    PreManual2 -.->|Preserved| PostManual2

    PreManual1 --> Analyze
    PreManual2 --> Analyze

    Analyze --> Check
    Check -->|No Conflicts| PostArch1
    Check -->|No Conflicts| PostArch2
    Check -->|No Conflicts| PostArch3

    Check -->|Conflict Found| Resolve
    Resolve -->|Renamed| PostArch1

    style PreManual1 fill:#4a9eff
    style PreManual2 fill:#4a9eff
    style PostManual1 fill:#4a9eff
    style PostManual2 fill:#4a9eff
    style PostArch1 fill:#90ee90
    style PostArch2 fill:#90ee90
    style PostArch3 fill:#90ee90
```

**Guarantees:**
- ✓ No overwriting of manual streams
- ✓ Conflict detection & resolution
- ✓ Coexistence of both types
- ✓ All streams accessible via existing commands

---

## 11. Error Handling Decision Tree

```mermaid
flowchart TD
    Start([User runs command])

    CheckGit{Git repo<br/>exists?}
    CheckCommits{Has<br/>commits?}
    CheckFormat{Semantic<br/>commits >20%?}
    CheckSize{Commits<br/>>1000?}

    NoGit["❌ Error: No Git<br/>Options: init, clone, manual"]
    NoCommits["❌ Error: No commits<br/>Options: wait, manual"]
    LowFormat["⚠️ Warning: Low semantic<br/>Options: continue, cancel"]
    LargeRepo["⚠️ Warning: Large repo<br/>Options: range, branch, limit"]

    Proceed[✓ Proceed with Analysis]
    Cancel([❌ Cancelled])
    Manual([Switch to Manual Mode])

    Start --> CheckGit
    CheckGit -->|No| NoGit
    NoGit --> Manual

    CheckGit -->|Yes| CheckCommits
    CheckCommits -->|No| NoCommits
    NoCommits --> Cancel

    CheckCommits -->|Yes| CheckFormat
    CheckFormat -->|<20%| LowFormat
    LowFormat -->|Continue| CheckSize
    LowFormat -->|Cancel| Cancel

    CheckFormat -->|>20%| CheckSize
    CheckSize -->|>1000| LargeRepo
    LargeRepo -->|Full analysis| Proceed
    LargeRepo -->|Scoped analysis| Proceed
    LargeRepo -->|Cancel| Cancel

    CheckSize -->|<1000| Proceed

    Proceed --> Success([✓ Analysis Complete])

    style NoGit fill:#ff6b6b
    style NoCommits fill:#ff6b6b
    style LowFormat fill:#ff9800
    style LargeRepo fill:#ff9800
    style Success fill:#90ee90
```

**Error Categories:**
- **Critical (Red):** Cannot proceed → Offer alternatives
- **Warning (Orange):** Can proceed with caution → User choice
- **Success (Green):** All checks passed → Continue

---

## 12. Data Flow Diagram

**Complete Flow from Git to Streams**

```mermaid
flowchart TB
    subgraph "Input Layer"
        Git[("Git Repository<br/>(.git/)")]
        Code[("Codebase<br/>(source files)")]
    end

    subgraph "Extraction Layer"
        GitCmd["git log<br/>git branch<br/>git tag"]
        FileList["ls -R<br/>file listing"]
    end

    subgraph "Processing Layer"
        Parser["Commit Parser<br/>(hash, author, date, msg)"]
        Semantic["Semantic Analyzer<br/>(type, scope, subject)"]
        Stats["File Stats<br/>(additions, deletions)"]
    end

    subgraph "Analysis Layer"
        Patterns["Pattern Detection<br/>(work rhythms, gaps)"]
        Boundaries["Boundary Detection<br/>(stream start/end)"]
        Goals["Goal Extraction<br/>(from commits)"]
        Checkpoints["Checkpoint Synthesis<br/>(milestones)"]
    end

    subgraph "Generation Layer"
        YAML["YAML Generator<br/>(stream.yaml files)"]
        Metadata["Metadata Builder<br/>(confidence, stats)"]
    end

    subgraph "Storage Layer"
        Memory[("Memory Store<br/>(.claude/analysis/)")]
        Streams[("Stream Database<br/>(.claude/streams/)")]
    end

    subgraph "Output Layer"
        UI["User Interface<br/>(CLI display)"]
        Commands["Work Streams Commands<br/>(/stream-list, etc.)"]
    end

    Git --> GitCmd
    Code --> FileList

    GitCmd --> Parser
    Parser --> Semantic
    Parser --> Stats

    Semantic --> Patterns
    Stats --> Patterns
    Patterns --> Boundaries

    Boundaries --> Goals
    Goals --> Checkpoints

    Checkpoints --> YAML
    Checkpoints --> Metadata

    YAML --> Memory
    Memory --> Streams
    Metadata --> Streams

    Streams --> UI
    Streams --> Commands

    style Git fill:#e1f5ff
    style Memory fill:#ffd700
    style Streams fill:#ffd700
    style UI fill:#90ee90
```

**Flow Summary:**
1. **Extract:** Git data via standard commands
2. **Process:** Parse commits into structured data
3. **Analyze:** Detect patterns and boundaries
4. **Generate:** Create stream YAML files
5. **Store:** Save to memory and streams database
6. **Output:** Display to user, enable commands

---

## Diagram Summary

### Visual Architecture Coverage

This document provides 12 comprehensive diagrams covering:

1. ✓ **System Architecture** - Overall component structure
2. ✓ **Agent Collaboration** - Sub-agent communication pattern
3. ✓ **Git Analysis** - Pipeline from git to patterns
4. ✓ **Context Management** - Session memory lifecycle
5. ✓ **Boundary Detection** - Algorithm flowchart
6. ✓ **User Interaction** - State machine for UX
7. ✓ **Session Memory** - Timeline of context evolution
8. ✓ **Sub-Agent Pattern** - Context isolation strategy
9. ✓ **Progressive Disclosure** - User experience journey
10. ✓ **Integration** - Coexistence with manual streams
11. ✓ **Error Handling** - Decision tree for failures
12. ✓ **Data Flow** - Complete end-to-end flow

### Design Principles Visualized

**Key patterns shown:**
- **Anthropic's Sub-Agent Architecture** → Diagram 2, 8
- **OpenAI's SummarizingSession** → Diagram 4, 7
- **Progressive Disclosure UX** → Diagram 6, 9
- **Context Engineering** → Diagram 4, 7, 8
- **Modular Architecture** → Diagram 1, 12

### Implementation Guidance

These diagrams serve as:
- **Architectural blueprints** for development
- **Communication tools** for team discussion
- **Validation artifacts** for design reviews
- **Documentation** for future maintenance

All diagrams use Mermaid syntax, renderable in GitHub, VS Code, and documentation tools.

---

**Document Version:** 1.0
**Last Updated:** 2025-11-02
**Format:** Mermaid Diagrams
**Companion:** v1.3.0-stream-archaeology-agent.md
